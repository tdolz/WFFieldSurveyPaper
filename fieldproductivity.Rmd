---
title: "TaraCDF_skyler"
author: "tara"
date: "5/20/2020"
output:
  pdf_document: default
  html_document: default
theme: readable
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, cache=TRUE)
```

## R Markdown

Converting this to markdown because it's easier to keep it together. 

**Analyses**  
+ Are there significant differences between occupied and available habitat *within each bay* in terms of temperature, salinity, dissolved oxygen.  
    - Weight catch by year. test stat is the permutation test. separate analyses for each bay.      
+ Are there differences *between bays* in time [date] and temperature when fish become fully selected to the gear [first peak in abundance].  
    - subset the data leading up to the peak abundance. find the temperature at the 50th percentile. plot all the bays on one graph. weight by bay. could do this separately for shinnecock peaks. 


**Total sampled area**
I did some rough area calculations in google earth based on previous sample maps. 
Sample maps can be found in the powerpoint "Sampling maps w stations for first SK grant 2016"
Shinnecock: 1.61 KM
Moriches: 1.49 KM
Jamaica Bay: 2.24 KM
Napeague Harbor: 1.98 KM
Cold Spring Pond: 0.52 KM  
Mattituck Creek: 0.37 KM

**I think I need to measure these for real somehow to determine which bay is the most productive per unit area**
https://jamesepaterson.github.io/jamespatersonblog/03_trackingworkshop_homeranges
we could do this by calculating minimum convex polygons but we'd have to fix lyndie's data for Cold Spring pond first. 
We should do this in a different R script.


```{r, echo=FALSE, warning=FALSE}
library("tidyr")
library("ggplot2")
library("plyr")
library("purrr")
library("dplyr")
library('ggrepel')
library("ggpmisc")
```

**My Data**
```{r}
#keeping everything in this folder
setwd("/Users//tdolan/Documents//R-Github//WFFieldSurveyPaper")
somedata3<-read.csv("skcompiled4gams2.csv", na.strings="", header=TRUE)
#somedata4 <-dplyr::select(somedata3,-rcpT,-std_cpue,-cpue)
```

## Catch per area at the peak ##
**Create the prepeak dataset**
```{r}
eday <- function(df){
  edays <-c()
for (i in 2:length(df$Date)){
  edays[i] <-df$Date[i]-df$Date[1]}
edays[1] <-0
df <-cbind(df,edays)
}
prepeak <-somedata3%>% dplyr::select(-minl, -maxl, -sdl, -distswept, -Tow, -Towindex) %>% mutate(Date=as.Date(Date))%>%
  unite(BayYear,Bay,Year, remove=FALSE)%>% arrange(Date)%>% base::split(.$BayYear) %>% map(eday)  #very important to arrange by date first. 
somedata3 <-mutate(somedata3,Date=as.Date(Date), Year=as.factor(Year), area=!is.na(area))
findpeak <-ddply(somedata3, Bay~Year~Date, summarize, new.cpue=sum(cpT)/sum(area))

#Mattituck
MTtows <-read.csv("mt YOY length and weight.csv",header=TRUE)
MTtows <-mutate(MTtows, len = as.numeric(Length..mm.), Tow=as.factor(Tow), Date=as.Date(Date)) %>%mutate(pres = ifelse(is.na(len),0,1))
MTcpt <-ddply(MTtows, Date~Tow, summarize, cpT=sum(pres)) %>% separate(Date, c("Year","m","d"),sep="-", remove=FALSE) %>% dplyr::rename(X=Tow)

#subset the dataset to before the peak by manually looking at what eday corresponds to the maximum cpue, the day before and after. 
# In Shinnecock we're including both weeks of the peak. 
prepeak_CSP10 <-filter(prepeak$`Cold Spring Pond_2010`, edays %in% c(0,7)) 
prepeak_J10 <-filter(prepeak$`Jamaica_2010`, edays %in% c(0,17))
prepeak_J11 <-filter(prepeak$`Jamaica_2011`, edays %in% c(0,28,42))
prepeak_J16 <-filter(prepeak$`Jamaica_2016`, edays %in% c(0,7))
prepeak_M10 <-filter(prepeak$`Moriches_2010`, edays %in% c(8,24,44))
prepeak_M11 <-filter(prepeak$`Moriches_2011`, edays %in% c(23,35,49))  
prepeak_M16 <-filter(prepeak$`Moriches_2016`, edays %in% c(23,30,37)) 
prepeak_N10 <-filter(prepeak$`Napeague_2010`, edays %in% c(0,21))
prepeak_N16 <-filter(prepeak$`Napeague_2016`, edays %in% c(21, 27, 35))
prepeak_Sh10 <-filter(prepeak$`Shinnecock_2010`, edays %in% c(9,27, 43)) #First peak
prepeak_Sh11 <-filter(prepeak$`Shinnecock_2011`, edays %in% c(0,25)) #First peak, second peak is at edays=79
prepeak_Sh16 <-filter(prepeak$`Shinnecock_2016`, edays %in% c(23, 30, 37, 44, 51, 56)) #1st peak only (23,30,37), both peaks(also 44,51,56)
prepeak_Sh17 <-filter(prepeak$`Shinnecock_2017`, edays %in% c(7,12, 20, 26,33,41,47)) #1st peak only (7,12,20,26), both peaks (also, 33,41,47)
prepeak_MT15 <-filter(MTcpt, Year=="2015") %>% eday() %>% filter(edays  %in% c(0, 13, 27)) %>% mutate(Year=as.integer(Year),X=as.integer(X), Bay="Mattituck")
prepeak_MT16 <<-filter(MTcpt, Year=="2016") %>% eday() %>% filter(edays  %in% c(11, 28, 39)) %>% mutate(Year=as.integer(Year),X=as.integer(X),Bay="Mattituck")
prepeak <-bind_rows(prepeak_CSP10,prepeak_J10,prepeak_J11,prepeak_J16,prepeak_M10,prepeak_M11,prepeak_M16,prepeak_N10,prepeak_N16,prepeak_Sh10,prepeak_Sh11,prepeak_Sh16,prepeak_Sh17, prepeak_MT15, prepeak_MT16) 


```

# **New version 8/23/2020** #

```{r}

#we don't want the standard deviation, we want the standard error of the mean. 
std <- function(x) sd(x)/sqrt(length(x))

## we want the mean catch per area swept across the peak ##
CPArea <-function(df) {
dat.eq1 <-ddply(df, Date~Year, summarize, area_swept=sum(area), total.catch=sum(cpT))%>% mutate(daily.cpue=total.catch/area_swept) 
df.prod <-ddply(dat.eq1, ~Year, summarize, avProd=mean(daily.cpue), seprod=std(daily.cpue))
df.prod}

#use function00
split.bay <- prepeak %>% base::split(.$Bay) 

a <-CPArea(split.bay$Shinnecock)
a <-mutate(a,Year=as.factor(Year), Bay="Shinnecock")
b <-CPArea(split.bay$Jamaica)
b <-mutate(b,Year=as.factor(Year), Bay="Jamaica") 
c <-CPArea(split.bay$Moriches)
c <-mutate(c,Year=as.factor(Year), Bay="Moriches")
d <-CPArea(split.bay$Napeague)
d<-mutate(d,Year=as.factor(Year), Bay="Napeague")
e <-CPArea(split.bay$`Cold Spring Pond`)
e <-mutate(e,Year=as.factor(Year), Bay="Cold Spring Pond")


###Mattituck###
# we do not have per tow area swept for mattituck readily available, so here is a workaround.
MTarea <-read.csv("some_mt_data.csv",header=TRUE) #per week area
MTarea <-dplyr::select(MTarea,Date,area)%>% mutate(Date=as.Date(Date))
prepeak_MT <-bind_rows(prepeak_MT15, prepeak_MT16) #per tow dataset

dat.eq1 <-ddply(prepeak_MT, Date~Year, summarize, total.catch=sum(cpT)) #now we have weekly catch
dat.eq1 <-left_join(dat.eq1, MTarea, by="Date") %>% mutate(daily.cpue=total.catch/area) %>%dplyr::select(Year,daily.cpue)
f <-ddply(dat.eq1, ~Year, summarize, avProd=mean(daily.cpue), seprod=std(daily.cpue))
f <-mutate(f,Year=as.factor(Year), Bay="Mattituck")

peakdens <-bind_rows(a,b,c,d,e,f)%>%unite(BayYear, Bay, Year, sep=" ", remove=FALSE)%>%arrange(Year)
peakdens <-mutate(peakdens, USE=avProd + seprod, LSE=avProd-seprod)

drabcolors <-c("#f6eff7","#d0d1e6","#a6bddb", "#67a9cf", "#1c9099", "#016450")

peakdens %>%
  filter(Year %in% c(2010,2011,2015,2016,2017))%>%
  ggplot(aes(x=BayYear,y=avProd, fill=Bay)) +
  geom_bar(stat="identity", position="dodge")+ #ylim(c(0,35000))+
  geom_errorbar(aes(ymin=LSE, ymax=USE),
              width=.2,position=position_dodge(.9), colour="lightgrey")+
  scale_fill_manual(values=drabcolors)+
  #facet_wrap(~year)+
  xlab("")+ylab("mean CPUE at peak abundance")+
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "white"))
#ggsave("bayprod_prepeak_cpuebothpeaksincluded.png", path="/Users/tdolan/documents/WF SK PROJ/Survey data/Field Survey Paper/final figures")
#dev.off()

```

The outliers are Mattituck 2015 and Napeague 2010. *what is driving these catches?*
I thought we had one tow in Mattituck that was like a thousand fish, but it's not showing up here, we're not seeing anomalously high tows driving the pattern. I think it is safe to continue. 
```{r}
prepeak <-separate(prepeak, Date, c("y","m","d"),remove=FALSE) %>% unite(Day,m,d,sep="-")%>% dplyr::select(-y)

prepeak %>%
  ggplot(aes(x=Day,y=cpT)) +
  geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  xlab("")+ylab("number of fish")+ ggtitle("Catch by tow")+
  facet_wrap(~Year, scales="free_x")+
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "white"))
#ggsave("catchbytow.png", path="/Users/tdolan/documents/WF SK PROJ/Survey data/Field Survey Paper/final figures")
#dev.off()
```

**Relationship to mortality and growth**
Let's combine these with growth and mortality estimates and see if we can find trends which would suggest density dependence. 
I don't think we should separate out the cohorts because small fish are still competing with big fish. 

```{r}
mandg <-read.csv("growthandmort.csv",header=TRUE) #growth and mortality. importing it instead of generating it, but later we should update so that it's generated by the other script and automatically written to a csv that this one can pick up. 
mandg <-unite(mandg, BayYear, Bay,Year, sep=" ", remove=FALSE) %>%mutate(Year=as.factor(Year))
peakdens2 <-mutate(peakdens,cohort="both", Year=as.factor(Year)) %>% dplyr::select(-USE,-LSE) 
peakdens2 <-left_join(peakdens2, mandg, by=c("Bay","Year","BayYear","cohort"))
```

**Visualize whether Napeague 2010 is an outlier**
```{r}
#plot labels.
peakdens2 %>%
  filter(cohort == "both")%>%
 filter(BayYear != "Napeague 2010")%>%
  ggplot(aes(x=avProd,y=mortality)) +
  geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  geom_label_repel(aes(label = alias), box.padding   = 0.35, point.padding = 0.5, segment.color = 'grey50')+
  xlab("mean CPUE at peak")+ylab("mortality")+ ggtitle("Mortality vs. Mean CPUE")+
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "black"))
```
From here we have decided to get rid of napeague 2010.

**Compare mortality vs. abundance at peak**
without napeague 2010
```{r}
### LOG FIT ###
peakdens3 <-filter(peakdens2, BayYear != "Napeague 2010", cohort=="both")
y <- peakdens3$mortality
x <-peakdens3$avProd

### Linear fit ###
#plot mortality vs. mean cpue. log fit. 
linM <-lm(y~x)
summary(linM)
AIC(linM)
peakdens2 %>%
  filter(cohort == "both")%>%
  #filter(BayYear != "Napeague 2010")%>%
  ggplot(aes(x=avProd,y=mortality, label=alias, color=Bay)) + 
  geom_text(check_overlap = TRUE)+
  #geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  #geom_label_repel(aes(label = alias), box.padding   = 0.35, point.padding = 0.5, segment.color = 'grey50')+
  stat_smooth(method="lm", se=FALSE, colour="black", linetype="dashed", size=0.2, fullrange=TRUE, data=peakdens3)+
  xlab("mean CPUE at peak")+ylab("mortality (Z)")+
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "black"))
#ggsave("mortVcpue_trend_LM_noNap.png", path="/Users/tdolan/documents/WF SK PROJ/Survey data/Field Survey Paper/final figures")
#dev.off()
```



**Growth vs. density**
Visualize with labels
```{r}
#plot labels.
peakdens2 %>%
  filter(cohort == "both")%>%
 # filter(BayYear != "Napeague 2010")%>%
  ggplot(aes(x=avProd,y=growth)) +
  geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  geom_label_repel(aes(label = alias, color=Bay), box.padding   = 0.35, label.size=NA, point.padding = 0.5, segment.color = 'grey50')+
  #geom_text_repel(aes(label = alias))+
  xlab("mean CPUE at peak")+ylab("growth")+ ggtitle("Growth vs. Mean CPUE at peak")+
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "black"))
```
Napeague 2010 (N10) does not seem like an outlier here. We will keep it. 


**Growth vs. density**
compare log and linear fits
```{r}

### LOG FIT ###
peakdens3 <-filter(peakdens2, cohort == "both")
y <- peakdens3$growth
x <-peakdens3$avProd

### Linear fit ###
#plot growth vs. mean cpue. log fit. 
linM <-lm(y~x)
summary(linM)
AIC(linM)
peakdens2 %>%
  filter(cohort == "both")%>%
  #filter(BayYear != "Napeague 2010")%>%
  ggplot(aes(x=avProd,y=growth, label=alias, color=Bay)) +
  #geom_text()+
  geom_text_repel()+
  #geom_label_repel(aes(label = alias, color=Bay), box.padding   = 0.35, label.size=NA, point.padding = 0.5, segment.color = 'grey50')+
  #geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  stat_smooth(method="lm", se=FALSE, colour="black", linetype="dashed", size=0.2, fullrange=TRUE)+
  xlab("mean CPUE at peak")+ylab("growth (G)")+ 
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "black"))
#ggsave("growVcpue_trend_LM.png", path="/Users/tdolan/documents/WF SK PROJ/Survey data/Field Survey Paper/final figures")
#dev.off()

### Linear fit NAPEAGUE REMOVED ###
#plot growth vs. mean cpue. log fit. 
peakdens3 <-filter(peakdens2, cohort == "both", BayYear != "Napeague 2010" )
linM <-lm(y~x)
summary(linM)
AIC(linM)
peakdens2 %>%
  filter(cohort == "both")%>%
  filter(BayYear != "Napeague 2010")%>%
  ggplot(aes(x=avProd,y=growth, label=alias, color=Bay)) +
  #geom_text()+
  geom_text_repel()+
  #geom_label_repel(aes(label = alias, color=Bay), box.padding   = 0.35, label.size=NA, point.padding = 0.5, segment.color = 'grey50')+
  #geom_point(aes(color=Bay))+
  scale_color_manual(values=drabcolors)+
  stat_smooth(method="lm", se=FALSE, colour="black", linetype="dashed", size=0.2, fullrange=TRUE, data=peakdens3)+
  xlab("mean CPUE at peak")+ylab("growth (G)")+ 
  theme(axis.text.x = element_text(angle = 90),panel.background = element_rect(fill = "white", colour = "black"))
#ggsave("growVcpue_trend_LM_NONAP.png", path="/Users/tdolan/documents/WF SK PROJ/Survey data/Field Survey Paper/final figures")
#dev.off()


```
#the linear fit looks better here. 

Slightly negative relationship between growth and CPUE suggests density dependence
